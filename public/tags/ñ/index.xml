<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ã‘, on Terminal</title>
    <link>//localhost:1313/tags/%C3%B1/</link>
    <description>Recent content in Ã‘, on Terminal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 11 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="//localhost:1313/tags/%C3%B1/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ğŸš€ Modelos de Lenguaje PequeÃ±os (SLMs): El Futuro de la IA AgÃ©ntica</title>
      <link>//localhost:1313/posts/los-small-llms-2025/</link>
      <pubDate>Fri, 11 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>//localhost:1313/posts/los-small-llms-2025/</guid>
      <description>&lt;p&gt;La inteligencia artificial agÃ©ntica estÃ¡ evolucionando rÃ¡pidamente, y todo apunta a que los &lt;strong&gt;Modelos de Lenguaje PequeÃ±os (SLMs)&lt;/strong&gt; tienen un rol protagÃ³nico en este futuro. Frente al dominio actual de los &lt;strong&gt;Modelos de Lenguaje Grandes (LLMs)&lt;/strong&gt;, los autores de este anÃ¡lisis argumentan que los SLMs son:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;âœ… Suficientemente potentes (V1)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;âš™ï¸ Operacionalmente mÃ¡s adecuados (V2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ğŸ’¸ Necesariamente mÃ¡s econÃ³micos (V3)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Veamos por quÃ© esta visiÃ³n estÃ¡ ganando terreno.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-por-quÃ©-los-slms-son-una-mejor-opciÃ³n&#34;&gt;ğŸ’¡ Â¿Por quÃ© los SLMs son una mejor opciÃ³n?&lt;/h2&gt;
&lt;h3 id=&#34;-a1-suficiente-capacidad-para-agentes&#34;&gt;ğŸ§  A1. Suficiente capacidad para agentes&lt;/h3&gt;
&lt;p&gt;Los SLMs han progresado hasta el punto de &lt;strong&gt;igualar o superar LLMs previos&lt;/strong&gt; en tareas clave:&lt;/p&gt;</description>
      <content>&lt;p&gt;La inteligencia artificial agÃ©ntica estÃ¡ evolucionando rÃ¡pidamente, y todo apunta a que los &lt;strong&gt;Modelos de Lenguaje PequeÃ±os (SLMs)&lt;/strong&gt; tienen un rol protagÃ³nico en este futuro. Frente al dominio actual de los &lt;strong&gt;Modelos de Lenguaje Grandes (LLMs)&lt;/strong&gt;, los autores de este anÃ¡lisis argumentan que los SLMs son:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;âœ… Suficientemente potentes (V1)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;âš™ï¸ Operacionalmente mÃ¡s adecuados (V2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ğŸ’¸ Necesariamente mÃ¡s econÃ³micos (V3)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Veamos por quÃ© esta visiÃ³n estÃ¡ ganando terreno.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-por-quÃ©-los-slms-son-una-mejor-opciÃ³n&#34;&gt;ğŸ’¡ Â¿Por quÃ© los SLMs son una mejor opciÃ³n?&lt;/h2&gt;
&lt;h3 id=&#34;-a1-suficiente-capacidad-para-agentes&#34;&gt;ğŸ§  A1. Suficiente capacidad para agentes&lt;/h3&gt;
&lt;p&gt;Los SLMs han progresado hasta el punto de &lt;strong&gt;igualar o superar LLMs previos&lt;/strong&gt; en tareas clave:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Modelos destacados&lt;/strong&gt;: Microsoft &lt;em&gt;Phi&lt;/em&gt; series, NVIDIA &lt;em&gt;Nemotron-H&lt;/em&gt;, &lt;em&gt;Huggingface SmolLM2&lt;/em&gt;, &lt;em&gt;Hymba-1.5B&lt;/em&gt;, &lt;em&gt;DeepSeek-R1-Distill&lt;/em&gt;, Salesforce &lt;em&gt;xLAM-2-8B&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Capacidades demostradas&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Razonamiento de sentido comÃºn&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Llamadas a herramientas&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GeneraciÃ³n de cÃ³digo&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Seguimiento de instrucciones&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ğŸ‘‰ Hoy, la limitaciÃ³n ya no es la cantidad de parÃ¡metros, sino &lt;strong&gt;cÃ³mo se entrena, se ajusta y se integra&lt;/strong&gt; el modelo.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-a2-mÃ¡s-econÃ³micos-para-sistemas-agÃ©nticos&#34;&gt;ğŸ’° A2. MÃ¡s econÃ³micos para sistemas agÃ©nticos&lt;/h3&gt;
&lt;p&gt;Los beneficios econÃ³micos son contundentes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Inferencia eficiente&lt;/strong&gt;: Un SLM de 7B parÃ¡metros es &lt;strong&gt;10â€“30x mÃ¡s barato&lt;/strong&gt; en latencia, energÃ­a y cÃ³mputo que un LLM de 70â€“175B.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fine-tuning Ã¡gil&lt;/strong&gt;: Puede ajustarse en solo &lt;strong&gt;unas horas de GPU&lt;/strong&gt;, ideal para especializar o corregir comportamientos rÃ¡pidamente.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Despliegue en el borde&lt;/strong&gt;: Pueden ejecutarse en &lt;strong&gt;GPUs personales&lt;/strong&gt;, sin conexiÃ³n a la nube, con mejor control de datos.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Modularidad tipo Lego&lt;/strong&gt;: En lugar de escalar un modelo monolÃ­tico, se ensamblan pequeÃ±os expertos, creando sistemas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;MÃ¡s baratos&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MÃ¡s rÃ¡pidos de depurar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MÃ¡s fÃ¡ciles de mantener y desplegar&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-a3-mayor-flexibilidad&#34;&gt;ğŸ§© A3. Mayor flexibilidad&lt;/h3&gt;
&lt;p&gt;Los SLMs son &lt;strong&gt;mÃ¡s fÃ¡ciles de entrenar, adaptar y desplegar&lt;/strong&gt;, lo que:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Permite mÃºltiples modelos expertos especializados&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Democratiza la creaciÃ³n de agentes IA&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reduce el riesgo de &lt;strong&gt;sesgos sistÃ©micos&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Estimula la &lt;strong&gt;innovaciÃ³n descentralizada&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-a4-y-si-el-llm-es-demasiado&#34;&gt;ğŸ”§ A4. Â¿Y si el LLM es â€œdemasiadoâ€?&lt;/h2&gt;
&lt;p&gt;En muchos casos, los agentes solo requieren una &lt;strong&gt;parte limitada&lt;/strong&gt; de la capacidad de un LLM. Un SLM bien ajustado para ciertas tareas especÃ­ficas puede:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ser &lt;strong&gt;mÃ¡s eficiente&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cometer &lt;strong&gt;menos errores&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ser &lt;strong&gt;mÃ¡s barato y rÃ¡pido&lt;/strong&gt; en producciÃ³n&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-a5-precisiÃ³n-de-formato&#34;&gt;ğŸ¯ A5. PrecisiÃ³n de formato&lt;/h3&gt;
&lt;p&gt;Las interacciones agÃ©nticas suelen depender de formatos estrictos: JSON, XML, Python&amp;hellip;&lt;br&gt;
Un SLM especializado en esos formatos es &lt;strong&gt;mÃ¡s confiable&lt;/strong&gt; que un LLM generalista que puede fallar con &lt;strong&gt;alucinaciones de formato&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-a6-sistemas-agÃ©nticos-son-naturalmente-heterogÃ©neos&#34;&gt;ğŸ§¬ A6. Sistemas agÃ©nticos son naturalmente heterogÃ©neos&lt;/h3&gt;
&lt;p&gt;En sistemas complejos, tiene sentido:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Usar un LLM como agente raÃ­z (gestiÃ³n general)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delegar tareas a mÃºltiples SLMs subordinados, cada uno optimizado para tareas especÃ­ficas&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Esto permite un equilibrio entre &lt;strong&gt;poder&lt;/strong&gt; y &lt;strong&gt;eficiencia&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-a7-aprendizaje-continuo&#34;&gt;ğŸ“ˆ A7. Aprendizaje continuo&lt;/h3&gt;
&lt;p&gt;Cada invocaciÃ³n de herramientas en un sistema agÃ©ntico genera datos de alta calidad que pueden usarse para:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Entrenar SLMs mÃ¡s expertos&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reemplazar LLMs en tareas especÃ­ficas&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mejorar iterativamente&lt;/strong&gt; el sistema&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-definiciones-operativas&#34;&gt;ğŸ“– Definiciones operativas&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;SLM (Small Language Model)&lt;/strong&gt;: Modelo que puede ejecutarse en dispositivos de consumo (como una laptop o GPU personal) con baja latencia.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LLM (Large Language Model)&lt;/strong&gt;: Modelo que &lt;strong&gt;no&lt;/strong&gt; cumple con las restricciones anteriores. En 2025, se considera SLM si tiene &lt;strong&gt;&amp;lt;10B parÃ¡metros&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-estado-actual-del-mercado&#34;&gt;ğŸ“Š Estado actual del mercado&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Se estima que la IA agÃ©ntica alcanzarÃ¡ los &lt;strong&gt;$200 mil millones en 2034&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;En 2024, se invirtieron &lt;strong&gt;$57 mil millones&lt;/strong&gt; en infraestructura LLM centralizada.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sin embargo, esta infraestructura &lt;strong&gt;asume&lt;/strong&gt; que el modelo LLM seguirÃ¡ siendo dominante&amp;hellip; Â¿y si no?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-puntos-de-vista-alternativos-y-refutaciones&#34;&gt;ğŸ§  Puntos de vista alternativos y refutaciones&lt;/h2&gt;
&lt;h3 id=&#34;-av1-los-llms-tienen-mejor-comprensiÃ³n-general&#34;&gt;âš ï¸ AV1: Los LLMs tienen mejor comprensiÃ³n general&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;RefutaciÃ³n&lt;/strong&gt;:&lt;br&gt;
La generalidad es Ãºtil, pero &lt;strong&gt;en sistemas agÃ©nticos avanzados&lt;/strong&gt;, las tareas se descomponen y distribuyen. AquÃ­ los &lt;strong&gt;SLMs especializados rinden mÃ¡s&lt;/strong&gt; por costo y precisiÃ³n.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-av2-los-costos-por-token-de-los-llms-son-menores-por-economÃ­a-de-escala&#34;&gt;ğŸ’¸ AV2: Los costos por token de los LLMs son menores por economÃ­a de escala&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Contraargumento&lt;/strong&gt;:&lt;br&gt;
Es vÃ¡lido, pero:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;La modularizaciÃ³n de la inferencia&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Las mejoras en programaciÃ³n eficiente&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;La caÃ­da de costos de hardware&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;hellip;hacen que los &lt;strong&gt;SLMs sigan siendo competitivos&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-av3-la-industria-ya-apostÃ³-por-llms-cambiar-es-difÃ­cil&#34;&gt;ğŸ§­ AV3: La industria ya apostÃ³ por LLMs, cambiar es difÃ­cil&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Respuesta&lt;/strong&gt;:&lt;br&gt;
SÃ­, hay inercia. Pero si los &lt;strong&gt;beneficios tÃ©cnicos y econÃ³micos de los SLMs&lt;/strong&gt; siguen creciendo, este cambio puede ser &lt;strong&gt;inevitable&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-conclusiÃ³n&#34;&gt;âœ… ConclusiÃ³n&lt;/h2&gt;
&lt;p&gt;Los &lt;strong&gt;SLMs no solo son el futuro&lt;/strong&gt;, ya estÃ¡n &lt;strong&gt;tomando el presente&lt;/strong&gt;.&lt;br&gt;
Por su potencia emergente, eficiencia, flexibilidad y facilidad de despliegue, representan una &lt;strong&gt;alternativa viable, Ã¡gil y democrÃ¡tica&lt;/strong&gt; frente a los gigantescos LLMs.&lt;/p&gt;
&lt;p&gt;Â¿El futuro de los agentes inteligentes?&lt;br&gt;
Probablemente &lt;strong&gt;pequeÃ±o, rÃ¡pido y especializado&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Â¿Quieres adaptar esto como publicaciÃ³n para tu portafolio, Medium o LinkedIn? Puedo ayudarte a ajustarlo con tono mÃ¡s divulgativo o tÃ©cnico segÃºn tu pÃºblico.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
