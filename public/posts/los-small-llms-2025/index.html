<!DOCTYPE html>
<html lang="en">
<head><script src="/iJKENNEDY/jkhzblog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=iJKENNEDY/jkhzblog/livereload" data-no-instant defer></script>
  
    <title>ğŸš€ Modelos de Lenguaje PequeÃ±os (SLMs): El Futuro de la IA AgÃ©ntica :: Terminal</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="La inteligencia artificial agÃ©ntica estÃ¡ evolucionando rÃ¡pidamente, y todo apunta a que los Modelos de Lenguaje PequeÃ±os (SLMs) tienen un rol protagÃ³nico en este futuro. Frente al dominio actual de los Modelos de Lenguaje Grandes (LLMs), los autores de este anÃ¡lisis argumentan que los SLMs son:
âœ… Suficientemente potentes (V1)
âš™ï¸ Operacionalmente mÃ¡s adecuados (V2)
ğŸ’¸ Necesariamente mÃ¡s econÃ³micos (V3)
Veamos por quÃ© esta visiÃ³n estÃ¡ ganando terreno.
ğŸ’¡ Â¿Por quÃ© los SLMs son una mejor opciÃ³n? ğŸ§  A1. Suficiente capacidad para agentes Los SLMs han progresado hasta el punto de igualar o superar LLMs previos en tareas clave:
" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="http://localhost:1313/iJKENNEDY/jkhzblog/posts/los-small-llms-2025/" />





  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/buttons.min.2bc533403a27dfe0e93105a92502b42ce4587e2e4a87d9f7d349e51e16e09478.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/code.min.00125962708925857e7b66dbc58391d55be1191a3d0ce2034de8c9cd2c481c36.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/fonts.min.4881f0c525f3ce2a1864fb6e96676396cebe1e6fcef1933e8e1dde7041004fb5.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/footer.min.2e3eb191baee58dd05a9f0104ac1fab0827bca7c64dafe0b2579f934c33a1d69.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/header.min.b6fb4423cf82a9f9d7abc9cd010223fa3d70a6526a3f28f8e17d814c06e18f9e.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/main.min.fe8dc560fccb53a458b0db19ccb7b265764ac46b68596b7e099c6793054dd457.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/menu.min.83637a90d903026bc280d3f82f96ceb06c5fc72b7c1a8d686afb5bbf818a29f7.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/pagination.min.82f6400eae7c7c6dc3c866733c2ec0579e4089608fea69400ff85b3880aa0d3c.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/post.min.fc74ca360273c1d828da3c02b8174eba435607b369d98418ccc6f2243cd4e75d.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/prism.min.9023bbc24533d09e97a51a0a42a5a7bfe4c591ae167c5551fb1d2191d11977c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/syntax.min.cc789ed9377260d7949ea4c18781fc58959a89287210fe4edbff44ebfc1511b6.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/terminal.min.dd0bf9c7cacb24c1b0184f52f1869b274e06689557468cc7030ccf632328eb97.css">

  
  <link rel="stylesheet" href="http://localhost:1313/iJKENNEDY/jkhzblog/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="http://localhost:1313/iJKENNEDY/jkhzblog/favicon.png">
<link rel="apple-touch-icon" href="http://localhost:1313/iJKENNEDY/jkhzblog/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="ğŸš€ Modelos de Lenguaje PequeÃ±os (SLMs): El Futuro de la IA AgÃ©ntica">
<meta property="og:description" content="La inteligencia artificial agÃ©ntica estÃ¡ evolucionando rÃ¡pidamente, y todo apunta a que los Modelos de Lenguaje PequeÃ±os (SLMs) tienen un rol protagÃ³nico en este futuro. Frente al dominio actual de los Modelos de Lenguaje Grandes (LLMs), los autores de este anÃ¡lisis argumentan que los SLMs son:
âœ… Suficientemente potentes (V1)
âš™ï¸ Operacionalmente mÃ¡s adecuados (V2)
ğŸ’¸ Necesariamente mÃ¡s econÃ³micos (V3)
Veamos por quÃ© esta visiÃ³n estÃ¡ ganando terreno.
ğŸ’¡ Â¿Por quÃ© los SLMs son una mejor opciÃ³n? ğŸ§  A1. Suficiente capacidad para agentes Los SLMs han progresado hasta el punto de igualar o superar LLMs previos en tareas clave:
" />
<meta property="og:url" content="http://localhost:1313/iJKENNEDY/jkhzblog/posts/los-small-llms-2025/" />
<meta property="og:site_name" content="Terminal" />

  <meta property="og:image" content="http://localhost:1313/iJKENNEDY/jkhzblog/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">


  <meta property="article:published_time" content="2025-07-11 00:00:00 &#43;0000 UTC" />












</head>
<body>


<div class="container">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;â–¾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/iJKENNEDY/jkhzblog/about">About</a></li>
        
      
        
          <li><a href="/iJKENNEDY/jkhzblog/showcase">Showcase</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/iJKENNEDY/jkhzblog/about" >About</a></li>
        
      
        
          <li><a href="/iJKENNEDY/jkhzblog/showcase" >Showcase</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<article class="post">
  <h1 class="post-title">
    <a href="http://localhost:1313/iJKENNEDY/jkhzblog/posts/los-small-llms-2025/">ğŸš€ Modelos de Lenguaje PequeÃ±os (SLMs): El Futuro de la IA AgÃ©ntica</a>
  </h1>
  <div class="post-meta"><time class="post-date">2025-07-11</time></div>

  
    <span class="post-tags">
      
      #<a href="http://localhost:1313/iJKENNEDY/jkhzblog/tags/llm/">LLM</a>&nbsp;
      
      #<a href="http://localhost:1313/iJKENNEDY/jkhzblog/tags/sllms/">sLLMs</a>&nbsp;
      
    </span>
  
  


  

  <div class="post-content"><div>
        <p>La inteligencia artificial agÃ©ntica estÃ¡ evolucionando rÃ¡pidamente, y todo apunta a que los <strong>Modelos de Lenguaje PequeÃ±os (SLMs)</strong> tienen un rol protagÃ³nico en este futuro. Frente al dominio actual de los <strong>Modelos de Lenguaje Grandes (LLMs)</strong>, los autores de este anÃ¡lisis argumentan que los SLMs son:</p>
<ul>
<li>
<p>âœ… Suficientemente potentes (V1)</p>
</li>
<li>
<p>âš™ï¸ Operacionalmente mÃ¡s adecuados (V2)</p>
</li>
<li>
<p>ğŸ’¸ Necesariamente mÃ¡s econÃ³micos (V3)</p>
</li>
</ul>
<p>Veamos por quÃ© esta visiÃ³n estÃ¡ ganando terreno.</p>
<hr>
<h2 id="-por-quÃ©-los-slms-son-una-mejor-opciÃ³n">ğŸ’¡ Â¿Por quÃ© los SLMs son una mejor opciÃ³n?<a href="#-por-quÃ©-los-slms-son-una-mejor-opciÃ³n" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<h3 id="-a1-suficiente-capacidad-para-agentes">ğŸ§  A1. Suficiente capacidad para agentes<a href="#-a1-suficiente-capacidad-para-agentes" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>Los SLMs han progresado hasta el punto de <strong>igualar o superar LLMs previos</strong> en tareas clave:</p>
<ul>
<li>
<p><strong>Modelos destacados</strong>: Microsoft <em>Phi</em> series, NVIDIA <em>Nemotron-H</em>, <em>Huggingface SmolLM2</em>, <em>Hymba-1.5B</em>, <em>DeepSeek-R1-Distill</em>, Salesforce <em>xLAM-2-8B</em></p>
</li>
<li>
<p><strong>Capacidades demostradas</strong>:</p>
<ul>
<li>
<p>Razonamiento de sentido comÃºn</p>
</li>
<li>
<p>Llamadas a herramientas</p>
</li>
<li>
<p>GeneraciÃ³n de cÃ³digo</p>
</li>
<li>
<p>Seguimiento de instrucciones</p>
</li>
</ul>
</li>
</ul>
<p>ğŸ‘‰ Hoy, la limitaciÃ³n ya no es la cantidad de parÃ¡metros, sino <strong>cÃ³mo se entrena, se ajusta y se integra</strong> el modelo.</p>
<hr>
<h3 id="-a2-mÃ¡s-econÃ³micos-para-sistemas-agÃ©nticos">ğŸ’° A2. MÃ¡s econÃ³micos para sistemas agÃ©nticos<a href="#-a2-mÃ¡s-econÃ³micos-para-sistemas-agÃ©nticos" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>Los beneficios econÃ³micos son contundentes:</p>
<ul>
<li>
<p><strong>Inferencia eficiente</strong>: Un SLM de 7B parÃ¡metros es <strong>10â€“30x mÃ¡s barato</strong> en latencia, energÃ­a y cÃ³mputo que un LLM de 70â€“175B.</p>
</li>
<li>
<p><strong>Fine-tuning Ã¡gil</strong>: Puede ajustarse en solo <strong>unas horas de GPU</strong>, ideal para especializar o corregir comportamientos rÃ¡pidamente.</p>
</li>
<li>
<p><strong>Despliegue en el borde</strong>: Pueden ejecutarse en <strong>GPUs personales</strong>, sin conexiÃ³n a la nube, con mejor control de datos.</p>
</li>
<li>
<p><strong>Modularidad tipo Lego</strong>: En lugar de escalar un modelo monolÃ­tico, se ensamblan pequeÃ±os expertos, creando sistemas:</p>
<ul>
<li>
<p>MÃ¡s baratos</p>
</li>
<li>
<p>MÃ¡s rÃ¡pidos de depurar</p>
</li>
<li>
<p>MÃ¡s fÃ¡ciles de mantener y desplegar</p>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="-a3-mayor-flexibilidad">ğŸ§© A3. Mayor flexibilidad<a href="#-a3-mayor-flexibilidad" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>Los SLMs son <strong>mÃ¡s fÃ¡ciles de entrenar, adaptar y desplegar</strong>, lo que:</p>
<ul>
<li>
<p>Permite mÃºltiples modelos expertos especializados</p>
</li>
<li>
<p>Democratiza la creaciÃ³n de agentes IA</p>
</li>
<li>
<p>Reduce el riesgo de <strong>sesgos sistÃ©micos</strong></p>
</li>
<li>
<p>Estimula la <strong>innovaciÃ³n descentralizada</strong></p>
</li>
</ul>
<hr>
<h2 id="-a4-y-si-el-llm-es-demasiado">ğŸ”§ A4. Â¿Y si el LLM es â€œdemasiadoâ€?<a href="#-a4-y-si-el-llm-es-demasiado" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<p>En muchos casos, los agentes solo requieren una <strong>parte limitada</strong> de la capacidad de un LLM. Un SLM bien ajustado para ciertas tareas especÃ­ficas puede:</p>
<ul>
<li>
<p>Ser <strong>mÃ¡s eficiente</strong></p>
</li>
<li>
<p>Cometer <strong>menos errores</strong></p>
</li>
<li>
<p>Ser <strong>mÃ¡s barato y rÃ¡pido</strong> en producciÃ³n</p>
</li>
</ul>
<hr>
<h3 id="-a5-precisiÃ³n-de-formato">ğŸ¯ A5. PrecisiÃ³n de formato<a href="#-a5-precisiÃ³n-de-formato" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>Las interacciones agÃ©nticas suelen depender de formatos estrictos: JSON, XML, Python&hellip;<br>
Un SLM especializado en esos formatos es <strong>mÃ¡s confiable</strong> que un LLM generalista que puede fallar con <strong>alucinaciones de formato</strong>.</p>
<hr>
<h3 id="-a6-sistemas-agÃ©nticos-son-naturalmente-heterogÃ©neos">ğŸ§¬ A6. Sistemas agÃ©nticos son naturalmente heterogÃ©neos<a href="#-a6-sistemas-agÃ©nticos-son-naturalmente-heterogÃ©neos" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>En sistemas complejos, tiene sentido:</p>
<ul>
<li>
<p>Usar un LLM como agente raÃ­z (gestiÃ³n general)</p>
</li>
<li>
<p>Delegar tareas a mÃºltiples SLMs subordinados, cada uno optimizado para tareas especÃ­ficas</p>
</li>
</ul>
<p>Esto permite un equilibrio entre <strong>poder</strong> y <strong>eficiencia</strong>.</p>
<hr>
<h3 id="-a7-aprendizaje-continuo">ğŸ“ˆ A7. Aprendizaje continuo<a href="#-a7-aprendizaje-continuo" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>Cada invocaciÃ³n de herramientas en un sistema agÃ©ntico genera datos de alta calidad que pueden usarse para:</p>
<ul>
<li>
<p>Entrenar SLMs mÃ¡s expertos</p>
</li>
<li>
<p>Reemplazar LLMs en tareas especÃ­ficas</p>
</li>
<li>
<p><strong>Mejorar iterativamente</strong> el sistema</p>
</li>
</ul>
<hr>
<h2 id="-definiciones-operativas">ğŸ“– Definiciones operativas<a href="#-definiciones-operativas" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<ul>
<li>
<p><strong>SLM (Small Language Model)</strong>: Modelo que puede ejecutarse en dispositivos de consumo (como una laptop o GPU personal) con baja latencia.</p>
</li>
<li>
<p><strong>LLM (Large Language Model)</strong>: Modelo que <strong>no</strong> cumple con las restricciones anteriores. En 2025, se considera SLM si tiene <strong>&lt;10B parÃ¡metros</strong>.</p>
</li>
</ul>
<hr>
<h2 id="-estado-actual-del-mercado">ğŸ“Š Estado actual del mercado<a href="#-estado-actual-del-mercado" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<ul>
<li>
<p>Se estima que la IA agÃ©ntica alcanzarÃ¡ los <strong>$200 mil millones en 2034</strong>.</p>
</li>
<li>
<p>En 2024, se invirtieron <strong>$57 mil millones</strong> en infraestructura LLM centralizada.</p>
</li>
<li>
<p>Sin embargo, esta infraestructura <strong>asume</strong> que el modelo LLM seguirÃ¡ siendo dominante&hellip; Â¿y si no?</p>
</li>
</ul>
<hr>
<h2 id="-puntos-de-vista-alternativos-y-refutaciones">ğŸ§  Puntos de vista alternativos y refutaciones<a href="#-puntos-de-vista-alternativos-y-refutaciones" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<h3 id="-av1-los-llms-tienen-mejor-comprensiÃ³n-general">âš ï¸ AV1: Los LLMs tienen mejor comprensiÃ³n general<a href="#-av1-los-llms-tienen-mejor-comprensiÃ³n-general" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p><strong>RefutaciÃ³n</strong>:<br>
La generalidad es Ãºtil, pero <strong>en sistemas agÃ©nticos avanzados</strong>, las tareas se descomponen y distribuyen. AquÃ­ los <strong>SLMs especializados rinden mÃ¡s</strong> por costo y precisiÃ³n.</p>
<hr>
<h3 id="-av2-los-costos-por-token-de-los-llms-son-menores-por-economÃ­a-de-escala">ğŸ’¸ AV2: Los costos por token de los LLMs son menores por economÃ­a de escala<a href="#-av2-los-costos-por-token-de-los-llms-son-menores-por-economÃ­a-de-escala" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p><strong>Contraargumento</strong>:<br>
Es vÃ¡lido, pero:</p>
<ul>
<li>
<p>La modularizaciÃ³n de la inferencia</p>
</li>
<li>
<p>Las mejoras en programaciÃ³n eficiente</p>
</li>
<li>
<p>La caÃ­da de costos de hardware</p>
</li>
</ul>
<p>&hellip;hacen que los <strong>SLMs sigan siendo competitivos</strong>.</p>
<hr>
<h3 id="-av3-la-industria-ya-apostÃ³-por-llms-cambiar-es-difÃ­cil">ğŸ§­ AV3: La industria ya apostÃ³ por LLMs, cambiar es difÃ­cil<a href="#-av3-la-industria-ya-apostÃ³-por-llms-cambiar-es-difÃ­cil" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p><strong>Respuesta</strong>:<br>
SÃ­, hay inercia. Pero si los <strong>beneficios tÃ©cnicos y econÃ³micos de los SLMs</strong> siguen creciendo, este cambio puede ser <strong>inevitable</strong>.</p>
<hr>
<h2 id="-conclusiÃ³n">âœ… ConclusiÃ³n<a href="#-conclusiÃ³n" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<p>Los <strong>SLMs no solo son el futuro</strong>, ya estÃ¡n <strong>tomando el presente</strong>.<br>
Por su potencia emergente, eficiencia, flexibilidad y facilidad de despliegue, representan una <strong>alternativa viable, Ã¡gil y democrÃ¡tica</strong> frente a los gigantescos LLMs.</p>
<p>Â¿El futuro de los agentes inteligentes?<br>
Probablemente <strong>pequeÃ±o, rÃ¡pido y especializado</strong>.</p>
<hr>
<p>Â¿Quieres adaptar esto como publicaciÃ³n para tu portafolio, Medium o LinkedIn? Puedo ayudarte a ajustarlo con tono mÃ¡s divulgativo o tÃ©cnico segÃºn tu pÃºblico.</p>

      </div></div>

  
    
<div class="pagination">
  <div class="pagination__title">
    <span class="pagination__title-h">Read other posts</span>
    <hr />
  </div>
  <div class="pagination__buttons">
    
    
    
      <a href="http://localhost:1313/iJKENNEDY/jkhzblog/posts/ingeniero-altamente-competitivo-y-valorado-en-una-empresa/" class="button inline next">
        Ingeniero Altamente Competitivo y Valorado en una Empresa
      </a>
    
  </div>
</div>


  

  
    

  
</article>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>Â© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/iJKENNEDY/jkhzblog/bundle.min.js"></script>





  
</div>

</body>
</html>
